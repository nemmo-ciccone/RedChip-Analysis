{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "from scipy.stats import mannwhitneyu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  8/26-9/16_total\n",
      "0   NVA.AX            -3.23\n",
      "1     CCTG             3.76\n",
      "2     RETO            -7.79\n",
      "3     DPRO           -20.99\n",
      "4     UAVS           -40.00\n",
      "..     ...              ...\n",
      "59     PED            11.55\n",
      "60    NCSM             0.14\n",
      "61    KLXE           -33.60\n",
      "62    AREC            -5.66\n",
      "63      AE             2.76\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_16660\\1908368385.py:54: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  nva_comp_df = nva_comp_df[['ticker', '8/26-9/16_total']].astype({'ticker': str, '8/26-9/16_total': float})\n"
     ]
    }
   ],
   "source": [
    "#Total movement 8/23 - 9/13\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        closing_price = stock_data['Close'].iloc[-1]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_total = ((closing_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"8/26-9/16_total\": round(percentage_total, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['NVA.AX', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', 'MVO', 'PRE', 'GLLI', 'WPRT', 'RR', 'LEV',\n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI',\n",
    "            'NWGL', 'PZG', 'WWR', 'XPL', 'HYMC', 'NB', 'FURY', 'VGZ', 'USAU', 'AMLI', 'AUST', 'GORO', 'TRX',\n",
    "            'THM', 'USEG', 'VIVK', 'PRT', 'DWSN', 'BATL', 'RCON', 'CRT', 'PED', 'NCSM', 'KLXE', 'AREC', 'AE',\n",
    "            ]\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-08-26\"\n",
    "end_date = \"2024-09-16\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "nva_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "nva_comp_df = nva_comp_df[['ticker', '8/26-9/16_total']].astype({'ticker': str, '8/26-9/16_total': float})\n",
    "\n",
    "print(nva_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 32.0\n",
      "p value: 1.0000\n",
      "Hodges-Lehmann Estimator: 0.43000000000000016\n",
      "Confidence Interval: (np.float64(-0.79), np.float64(0.52))\n"
     ]
    }
   ],
   "source": [
    "just_nva_total = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '8/26-9/16_total'].values[0]\n",
    "rest_totals = nva_comp_df.loc[nva_comp_df['ticker'] != 'NVA.AX', '8/26-9/16_total']\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_nva_total, rest_totals, alpha=0.05):\n",
    "    if np.isscalar(just_nva_total):\n",
    "        just_nva_total = [just_nva_total]\n",
    "    if np.isscalar(rest_totals):\n",
    "        rest_totals = [rest_totals]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_total for x2 in rest_totals]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_nva_total), len(rest_totals)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_total, rest_totals, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_total, rest_totals, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  8/22-9/16_peak\n",
      "0   NVA.AX           18.75\n",
      "1     CCTG           15.98\n",
      "2     RETO           80.20\n",
      "3     DPRO            0.71\n",
      "4     UAVS           30.00\n",
      "..     ...             ...\n",
      "59     PED           18.99\n",
      "60    NCSM            6.33\n",
      "61    KLXE            7.13\n",
      "62    AREC            7.46\n",
      "63      AE           12.52\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_16660\\661485946.py:48: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  nva_comp_df = nva_comp_df[['ticker', '8/22-9/16_peak']].astype({'ticker': str, '8/22-9/16_peak': float})\n"
     ]
    }
   ],
   "source": [
    "# Peak movement 8/22 - 9/16\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_peak = ((peak_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"8/22-9/16_peak\": round(percentage_peak, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['NVA.AX', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', 'MVO', 'PRE', 'GLLI', 'WPRT', 'RR', 'LEV',\n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI',\n",
    "            'NWGL', 'PZG', 'WWR', 'XPL', 'HYMC', 'NB', 'FURY', 'VGZ', 'USAU', 'AMLI', 'AUST', 'GORO', 'TRX',\n",
    "            'THM', 'USEG', 'VIVK', 'PRT', 'DWSN', 'BATL', 'RCON', 'CRT', 'PED', 'NCSM', 'KLXE', 'AREC', 'AE',\n",
    "            ]\n",
    "\n",
    "start_date = \"2024-08-22\"\n",
    "end_date = \"2024-09-17\"\n",
    "\n",
    "data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "nva_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "nva_comp_df = nva_comp_df[['ticker', '8/22-9/16_peak']].astype({'ticker': str, '8/22-9/16_peak': float})\n",
    "\n",
    "print(nva_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 46.0\n",
      "p value: 0.4485\n",
      "Hodges-Lehmann Estimator: 11.530000000000001\n",
      "Confidence Interval: (np.float64(11.25), np.float64(11.620000000000001))\n"
     ]
    }
   ],
   "source": [
    "just_nva_peak = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '8/22-9/16_peak'].values[0]\n",
    "rest_peaks = nva_comp_df.loc[nva_comp_df['ticker'] != 'NVA.AX', '8/22-9/16_peak']\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_nva_peak, rest_peaks, alpha=0.05):\n",
    "    if np.isscalar(just_nva_peak):\n",
    "        just_nva_peak = [just_nva_peak]\n",
    "    if np.isscalar(rest_peaks):\n",
    "        rest_peaks = [rest_peaks]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_peak for x2 in rest_peaks]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_nva_peak), len(rest_peaks)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_peak, rest_peaks, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_peak, rest_peaks, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  9/30-10/24_total\n",
      "0   NVA.AX             92.59\n",
      "1     CCTG             41.76\n",
      "2     RETO            -14.84\n",
      "3     DPRO             10.66\n",
      "4     UAVS            -87.26\n",
      "..     ...               ...\n",
      "59     PED             -0.54\n",
      "60    NCSM            -11.65\n",
      "61    KLXE            -18.85\n",
      "62    AREC             12.46\n",
      "63      AE              5.65\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_16660\\349169284.py:54: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  nva_comp_df = nva_comp_df[['ticker', '9/30-10/24_total']].astype({'ticker': str, '9/30-10/24_total': float})\n"
     ]
    }
   ],
   "source": [
    "#Total movement 9/30 - 10/24\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        closing_price = stock_data['Close'].iloc[-1]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_total = ((closing_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"9/30-10/24_total\": round(percentage_total, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['NVA.AX', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', 'MVO', 'PRE', 'GLLI', 'WPRT', 'RR', 'LEV',\n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI',\n",
    "            'NWGL', 'PZG', 'WWR', 'XPL', 'HYMC', 'NB', 'FURY', 'VGZ', 'USAU', 'AMLI', 'AUST', 'GORO', 'TRX',\n",
    "            'THM', 'USEG', 'VIVK', 'PRT', 'DWSN', 'BATL', 'RCON', 'CRT', 'PED', 'NCSM', 'KLXE', 'AREC', 'AE',\n",
    "            ]\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-09-30\"\n",
    "end_date = \"2024-10-24\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "nva_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "nva_comp_df = nva_comp_df[['ticker', '9/30-10/24_total']].astype({'ticker': str, '9/30-10/24_total': float})\n",
    "\n",
    "print(nva_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1044\n",
      "Hodges-Lehmann Estimator: 91.4\n",
      "Confidence Interval: (np.float64(90.66), np.float64(91.4))\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 9/30 - 10/24\n",
    "\n",
    "just_nva_total = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '9/30-10/24_total'].values[0]\n",
    "rest_total = nva_comp_df['9/30-10/24_total'][1:]\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_nva_total, rest_total, alpha=0.05):\n",
    "    if np.isscalar(just_nva_total):\n",
    "        just_nva_total = [just_nva_total]\n",
    "    if np.isscalar(rest_total):\n",
    "        rest_total = [rest_total]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_total for x2 in rest_total]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_nva_total), len(rest_total)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_total, rest_total, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_total, rest_total, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1044\n",
      "Hodges-Lehmann Estimator: 91.4\n",
      "Confidence Interval: (np.float64(-10.920000000000002), np.float64(84.26))\n"
     ]
    }
   ],
   "source": [
    "just_nva_total = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '9/30-10/24_total'].values[0]\n",
    "rest_totals = nva_comp_df.loc[nva_comp_df['ticker'] != 'NVA.AX', '9/30-10/24_total']\n",
    "\n",
    "\n",
    "def hodges_lehmann_interval(just_nva_total, rest_totals, alpha=0.05):\n",
    "    if np.isscalar(just_nva_total):\n",
    "        just_nva_total = [just_nva_total]\n",
    "    if np.isscalar(rest_totals):\n",
    "        rest_totals = [rest_totals]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_total for x2 in rest_totals]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n = len(pairwise_differences)\n",
    "\n",
    "    _, u_stat = mannwhitneyu(just_nva_total, rest_totals, alternative='two-sided')\n",
    "\n",
    "    lower_rank = int(max(0, u_stat - 1.96 * np.sqrt(n)))  # Ensure lower rank is >= 0\n",
    "    upper_rank = int(min(n - 1, u_stat + 1.96 * np.sqrt(n)))  # Ensure upper rank < n\n",
    "\n",
    "    lower_bound = pairwise_differences[lower_rank]\n",
    "    upper_bound = pairwise_differences[upper_rank]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_total, rest_totals, alternative = 'two-sided')\n",
    "\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_total, rest_totals, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_gp_peak), len(rest_peak)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker  9/30-10/24_peak\n",
      "0   NVA.AX           103.70\n",
      "1     CCTG            86.47\n",
      "2     RETO            21.09\n",
      "3     DPRO            63.52\n",
      "4     UAVS             0.00\n",
      "..     ...              ...\n",
      "59     PED            12.15\n",
      "60    NCSM             0.00\n",
      "61    KLXE             9.24\n",
      "62    AREC            31.43\n",
      "63      AE            12.09\n",
      "\n",
      "[64 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_16660\\692376834.py:52: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  nva_comp_df = nva_comp_df[['ticker', '9/30-10/24_peak']].astype({'ticker': str, '9/30-10/24_peak': float})\n"
     ]
    }
   ],
   "source": [
    "#Peak movement 9/30 - 10/24\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_peak = ((peak_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"9/30-10/24_peak\": round(percentage_peak, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['NVA.AX', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', 'MVO', 'PRE', 'GLLI', 'WPRT', 'RR', 'LEV',\n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI',\n",
    "            'NWGL', 'PZG', 'WWR', 'XPL', 'HYMC', 'NB', 'FURY', 'VGZ', 'USAU', 'AMLI', 'AUST', 'GORO', 'TRX',\n",
    "            'THM', 'USEG', 'VIVK', 'PRT', 'DWSN', 'BATL', 'RCON', 'CRT', 'PED', 'NCSM', 'KLXE', 'AREC', 'AE',\n",
    "            ]\n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-09-30\"\n",
    "end_date = \"2024-10-24\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "nva_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "nva_comp_df = nva_comp_df[['ticker', '9/30-10/24_peak']].astype({'ticker': str, '9/30-10/24_peak': float})\n",
    "\n",
    "print(nva_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1044\n",
      "Hodges-Lehmann Estimator: 91.61\n",
      "Confidence Interval: (np.float64(90.76), np.float64(91.77000000000001))\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 9/30 - 10/24\n",
    "\n",
    "just_nva_peak = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '9/30-10/24_peak'].values[0]\n",
    "rest_peak = nva_comp_df['9/30-10/24_peak'][1:]\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_nva_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_nva_peak):\n",
    "        just_nva_peak = [just_nva_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_nva_peak), len(rest_peak)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1044\n",
      "Hodges-Lehmann Estimator: 91.61\n",
      "Confidence Interval: (np.float64(-69.55), np.float64(72.03))\n"
     ]
    }
   ],
   "source": [
    "#Peak movement 9/30 - 10/24\n",
    "\n",
    "just_nva_peak = nva_comp_df.loc[nva_comp_df['ticker'] == 'NVA.AX', '9/30-10/24_peak'].values[0]\n",
    "rest_peaks = nva_comp_df.loc[nva_comp_df['ticker'] != 'NVA.AX', '9/30-10/24_peak']\n",
    "\n",
    "def hodges_lehmann_interval(just_nva_peak, rest_peaks, alpha=0.05):\n",
    "    if np.isscalar(just_nva_peak):\n",
    "        just_nva_peak = [just_nva_peak]\n",
    "    if np.isscalar(rest_peaks):\n",
    "        rest_peaks = [rest_peaks]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_nva_peak for x2 in rest_peaks]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n = len(pairwise_differences)\n",
    "\n",
    "    _, u_stat = mannwhitneyu(just_nva_peak, rest_peaks, alternative='two-sided')\n",
    "\n",
    "    lower_rank = int(max(0, u_stat - 1.96 * np.sqrt(n)))  # Ensure lower rank is >= 0\n",
    "    upper_rank = int(min(n - 1, u_stat + 1.96 * np.sqrt(n)))  # Ensure upper rank < n\n",
    "\n",
    "    lower_bound = pairwise_differences[lower_rank]\n",
    "    upper_bound = pairwise_differences[upper_rank]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_nva_peak, rest_peaks, alternative = 'two-sided')\n",
    "\n",
    "\n",
    "result = hodges_lehmann_interval(just_nva_peak, rest_peaks, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined p-value using Fisher's method: 0.1902\n"
     ]
    }
   ],
   "source": [
    "#For combining peak movement p - values\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def fisher_combined_pvalue(p_values):\n",
    " \n",
    "    chi2_stat = -2 * np.sum(np.log(p_values))\n",
    "\n",
    "    df = 2 * len(p_values)\n",
    "\n",
    "    combined_p_value = 1 - chi2.cdf(chi2_stat, df)\n",
    "\n",
    "    return combined_p_value\n",
    "\n",
    "p_values = [0.4485, 0.1044]  # List of individual p-values\n",
    "combined_p_value = fisher_combined_pvalue(p_values)\n",
    "\n",
    "print(f\"Combined p-value using Fisher's method: {combined_p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

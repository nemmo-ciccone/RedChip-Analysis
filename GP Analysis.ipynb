{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  9/9-9/20_total\n",
      "0      GP           43.19\n",
      "1     CVR           12.10\n",
      "2    JCTC           15.15\n",
      "3     BRN            6.48\n",
      "4    FCUV           -0.53\n",
      "..    ...             ...\n",
      "62   JUNE            1.75\n",
      "63    APT            2.76\n",
      "64   TPIC           23.12\n",
      "65    GWH           -1.92\n",
      "66   PPSI           10.65\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_9604\\3778959935.py:54: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gp_comp_df = gp_comp_df[['ticker', '9/9-9/20_total']].astype({'ticker': str, '9/9-9/20_total': float})\n"
     ]
    }
   ],
   "source": [
    "# Total movement 9/9 - 9/20\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        closing_price = stock_data['Close'].iloc[-1]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_total = ((closing_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"9/9-9/20_total\": round(percentage_total, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['GP', 'CVR', 'JCTC', 'BRN', 'FCUV', 'SIF', 'DAIO', 'SVT', 'OESX', 'AP',\n",
    "           'OPTT', 'MESA', 'GLBS', 'FLUX', 'GTEC', 'FTEK', 'APWC', 'EDRY', 'SYPR', 'BWEN',\n",
    "           'BEEM', 'CVU', 'ELSE', 'TOMZ', 'UGRO', 'OP', 'ASTC', 'PETZ', 'EKSO', 'AQMS',\n",
    "           'YHGJ', 'AIRI', 'PRZO', 'OCC', 'LIQT', 'HLP', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', \n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI']\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-09-09\"\n",
    "end_date = \"2024-09-20\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "gp_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "gp_comp_df = gp_comp_df[['ticker', '9/9-9/20_total']].astype({'ticker': str, '9/9-9/20_total': float})\n",
    "\n",
    "print(gp_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data does not appear normally distributed (reject H0)\n"
     ]
    }
   ],
   "source": [
    "gp_total= gp_comp_df['9/9-9/20_total']\n",
    "\n",
    "stat, p_value = stats.shapiro(gp_total)\n",
    "\n",
    "if p_value > 0.05:\n",
    "    print(\"Data appears normally distributed (fail to reject H0)\")\n",
    "else:\n",
    "    print(\"Data does not appear normally distributed (reject H0)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 64.0\n",
      "p value: 0.0896\n"
     ]
    }
   ],
   "source": [
    "#For total price movement 9/9-9/20\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "just_gp_total = gp_comp_df.loc[gp_comp_df['ticker'] == 'GP', '9/9-9/20_total'].values[0]\n",
    "\n",
    "# Extract the values for the rest of the stocks\n",
    "rest_totals = gp_comp_df.loc[gp_comp_df['ticker'] != 'GP', '9/9-9/20_total']\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_total, rest_totals, alternative = 'two-sided')\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 64.0\n",
      "p value: 0.0896\n",
      "Hodges-Lehmann Estimator: 40.59\n",
      "Confidence Interval: (np.float64(40.169999999999995), np.float64(40.839999999999996))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_gp_total, rest_totals, alpha=0.05):\n",
    "    if np.isscalar(just_gp_total):\n",
    "        just_gp_total = [just_gp_total]\n",
    "    if np.isscalar(rest_totals):\n",
    "        rest_totals = [rest_totals]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_total for x2 in rest_totals]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_gp_total), len(rest_totals)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_total, rest_totals, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_total, rest_totals, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  9/9-9/16_peak\n",
      "0      GP         121.19\n",
      "1     CVR           2.40\n",
      "2    JCTC          11.19\n",
      "3     BRN           5.09\n",
      "4    FCUV          44.47\n",
      "..    ...            ...\n",
      "62   JUNE          11.64\n",
      "63    APT           0.00\n",
      "64   TPIC          24.74\n",
      "65    GWH           7.49\n",
      "66   PPSI          18.60\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_9604\\184896813.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gp_comp_df = gp_comp_df[['ticker', '9/9-9/16_peak']].astype({'ticker': str, '9/9-9/16_peak': float})\n"
     ]
    }
   ],
   "source": [
    "#Peak movement 9/9-9/20\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_peak = ((peak_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"9/9-9/16_peak\": round(percentage_peak, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['GP', 'CVR', 'JCTC', 'BRN', 'FCUV', 'SIF', 'DAIO', 'SVT', 'OESX', 'AP',\n",
    "           'OPTT', 'MESA', 'GLBS', 'FLUX', 'GTEC', 'FTEK', 'APWC', 'EDRY', 'SYPR', 'BWEN',\n",
    "           'BEEM', 'CVU', 'ELSE', 'TOMZ', 'UGRO', 'OP', 'ASTC', 'PETZ', 'EKSO', 'AQMS',\n",
    "           'YHGJ', 'AIRI', 'PRZO', 'OCC', 'LIQT', 'HLP', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', \n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI']\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-09-09\"\n",
    "end_date = \"2024-09-16\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "gp_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "gp_comp_df = gp_comp_df[['ticker', '9/9-9/16_peak']].astype({'ticker': str, '9/9-9/16_peak': float})\n",
    "\n",
    "print(gp_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistic: 66.0\n",
      "p value: 0.0928\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 9/9-9/16\n",
    "\n",
    "just_gp_peak = gp_comp_df.loc[0, '9/9-9/16_peak']\n",
    "rest_peak = gp_comp_df['9/9-9/16_peak'][1:]\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "print(f'Mann Whitney U Statistic: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 66.0\n",
      "p value: 0.0928\n",
      "Hodges-Lehmann Estimator: 112.25999999999999\n",
      "Confidence Interval: (np.float64(56.849999999999994), np.float64(106.19))\n"
     ]
    }
   ],
   "source": [
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n = len(pairwise_differences)\n",
    "\n",
    "    _, u_stat = mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "    lower_rank = int(max(0, u_stat - 1.96 * np.sqrt(n)))  # Ensure lower rank is >= 0\n",
    "    upper_rank = int(min(n - 1, u_stat + 1.96 * np.sqrt(n)))  # Ensure upper rank < n\n",
    "\n",
    "    lower_bound = pairwise_differences[lower_rank]\n",
    "    upper_bound = pairwise_differences[upper_rank]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 66.0\n",
      "p value: 0.0928\n",
      "Hodges-Lehmann Estimator: 112.25999999999999\n",
      "Confidence Interval: (np.float64(111.92999999999999), np.float64(113.28))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_gp_peak), len(rest_peak)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_9604\\1570367238.py:56: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gp_comp_df = gp_comp_df[['ticker', '10/23-10/30_total']].astype({'ticker': str, '10/23-10/30_total': float})\n"
     ]
    }
   ],
   "source": [
    "#For total movement 10/23-10/30\n",
    "#(Useless to include because negative)\n",
    "\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        closing_price = stock_data['Close'].iloc[-1]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_total = ((closing_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"10/23-10/30_total\": round(percentage_total, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['GP', 'CVR', 'JCTC', 'BRN', 'FCUV', 'SIF', 'DAIO', 'SVT', 'OESX', 'AP',\n",
    "           'OPTT', 'MESA', 'GLBS', 'FLUX', 'GTEC', 'FTEK', 'APWC', 'EDRY', 'SYPR', 'BWEN',\n",
    "           'BEEM', 'CVU', 'ELSE', 'TOMZ', 'UGRO', 'OP', 'ASTC', 'PETZ', 'EKSO', 'AQMS',\n",
    "           'YHGJ', 'AIRI', 'PRZO', 'OCC', 'LIQT', 'HLP', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', \n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI']\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-10-23\"\n",
    "end_date = \"2024-10-30\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "gp_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "gp_comp_df = gp_comp_df[['ticker', '10/23-10/30_total']].astype({'ticker': str, '10/23-10/30_total': float})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 2.0\n",
      "p value: 0.1148\n"
     ]
    }
   ],
   "source": [
    "#For total movement 10/23-10/30\n",
    "#(Useless to include because negative)\n",
    "\n",
    "just_gp_total = gp_comp_df.loc[0, '10/23-10/30_total']\n",
    "rest_totals = gp_comp_df['10/23-10/30_total'][1:]\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_total, rest_totals, alternative = 'two-sided')\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  10/23-10/25_peak\n",
      "0      GP             49.19\n",
      "1     CVR              2.72\n",
      "2    JCTC              5.06\n",
      "3     BRN              1.48\n",
      "4    FCUV              3.35\n",
      "..    ...               ...\n",
      "62   JUNE              9.32\n",
      "63    APT              1.35\n",
      "64   TPIC              2.27\n",
      "65    GWH              4.57\n",
      "66   PPSI              3.06\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_9604\\515122368.py:53: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gp_comp_df = gp_comp_df[['ticker', '10/23-10/25_peak']].astype({'ticker': str, '10/23-10/25_peak': float})\n"
     ]
    }
   ],
   "source": [
    "#Peak movement 10/23 - 10/25\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_peak = ((peak_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"10/23-10/25_peak\": round(percentage_peak, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['GP', 'CVR', 'JCTC', 'BRN', 'FCUV', 'SIF', 'DAIO', 'SVT', 'OESX', 'AP',\n",
    "           'OPTT', 'MESA', 'GLBS', 'FLUX', 'GTEC', 'FTEK', 'APWC', 'EDRY', 'SYPR', 'BWEN',\n",
    "           'BEEM', 'CVU', 'ELSE', 'TOMZ', 'UGRO', 'OP', 'ASTC', 'PETZ', 'EKSO', 'AQMS',\n",
    "           'YHGJ', 'AIRI', 'PRZO', 'OCC', 'LIQT', 'HLP', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', \n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI']\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-10-23\"\n",
    "end_date = \"2024-10-25\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "gp_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "gp_comp_df = gp_comp_df[['ticker', '10/23-10/25_peak']].astype({'ticker': str, '10/23-10/25_peak': float})\n",
    "\n",
    "print(gp_comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistic: 64.0\n",
      "p value: 0.1143\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 10/23-10/25\n",
    "\n",
    "just_gp_peak = gp_comp_df.loc[0, '10/23-10/25_peak']\n",
    "rest_peak = gp_comp_df['10/23-10/25_peak'][1:]\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "print(f'Mann Whitney U Statistic: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 64.0\n",
      "p value: 0.1143\n",
      "Hodges-Lehmann Estimator: 46.385\n",
      "Confidence Interval: (np.float64(-80.28999999999999), np.float64(44.17))\n"
     ]
    }
   ],
   "source": [
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n = len(pairwise_differences)\n",
    "\n",
    "    _, u_stat = mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "    lower_rank = int(max(0, u_stat - 1.96 * np.sqrt(n)))  # Ensure lower rank is >= 0\n",
    "    upper_rank = int(min(n - 1, u_stat + 1.96 * np.sqrt(n)))  # Ensure upper rank < n\n",
    "\n",
    "    lower_bound = pairwise_differences[lower_rank]\n",
    "    upper_bound = pairwise_differences[upper_rank]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 64.0\n",
      "p value: 0.1143\n",
      "Hodges-Lehmann Estimator: 46.385\n",
      "Confidence Interval: (np.float64(46.129999999999995), np.float64(46.47))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_gp_peak), len(rest_peak)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ticker  11/26-11/27_peak\n",
      "0      GP             10.99\n",
      "1     CVR             -2.67\n",
      "2    JCTC              5.41\n",
      "3     BRN              4.12\n",
      "4    FCUV              4.10\n",
      "..    ...               ...\n",
      "62   JUNE              0.43\n",
      "63    APT             -0.56\n",
      "64   TPIC             -9.50\n",
      "65    GWH              3.22\n",
      "66   PPSI             -0.50\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\19413\\AppData\\Local\\Temp\\ipykernel_9604\\646061105.py:55: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  gp_comp_df = gp_comp_df[['ticker', '11/26-11/27_peak']].astype({'ticker': str, '11/26-11/27_peak': float})\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 11/26-11/27\n",
    "\n",
    "def get_stock_movement(ticker, start_date, end_date):\n",
    "    try:\n",
    "        # Adjust the end_date to include the intended day\n",
    "        end_date_adjusted = (datetime.strptime(end_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date_adjusted, progress=False)\n",
    "\n",
    "        if stock_data.empty:\n",
    "            return {\"error\": f\"No data found for {ticker} between {start_date} and {end_date}\"}\n",
    "\n",
    "        opening_price = stock_data['Open'].iloc[0]\n",
    "        closing_price = stock_data['Close'].iloc[-1]\n",
    "        peak_price = stock_data['High'].max()\n",
    "\n",
    "        percentage_total = ((closing_price - opening_price) / opening_price) * 100\n",
    "\n",
    "        return {\n",
    "            \"ticker\": ticker,\n",
    "            \"11/26-11/27_peak\": round(percentage_total, 2)  # Rounded to two decimal places\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['GP', 'CVR', 'JCTC', 'BRN', 'FCUV', 'SIF', 'DAIO', 'SVT', 'OESX', 'AP',\n",
    "           'OPTT', 'MESA', 'GLBS', 'FLUX', 'GTEC', 'FTEK', 'APWC', 'EDRY', 'SYPR', 'BWEN',\n",
    "           'BEEM', 'CVU', 'ELSE', 'TOMZ', 'UGRO', 'OP', 'ASTC', 'PETZ', 'EKSO', 'AQMS',\n",
    "           'YHGJ', 'AIRI', 'PRZO', 'OCC', 'LIQT', 'HLP', 'CCTG', 'RETO', 'DPRO', 'UAVS', 'GDC', 'KNW', \n",
    "           'BNGO', 'NISN', 'HUDI', 'DTCK', 'ZKIN', 'PMEC', 'HYFM', 'TPCS', 'FEAM', 'AXDX', 'VGAS', 'MTEN',\n",
    "            'DSWL', 'GLST', 'MIND', 'FSI', 'IPWR', 'ESGL', 'CPTN', 'CLIR', 'JUNE', 'APT', 'TPIC', 'GWH', 'PPSI']\n",
    "           \n",
    "\n",
    "# Start and end dates\n",
    "start_date = \"2024-11-26\"\n",
    "end_date = \"2024-11-27\"\n",
    "\n",
    "# Initialize empty list to hold the data\n",
    "data = []\n",
    "\n",
    "# Loop through tickers\n",
    "for ticker in tickers:\n",
    "    result = get_stock_movement(ticker, start_date, end_date)\n",
    "    if \"error\" in result:\n",
    "        print(f\"Error for {ticker}: {result['error']}\")\n",
    "    else:\n",
    "        data.append(result)\n",
    "\n",
    "# Create DataFrame\n",
    "gp_comp_df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame with the specified columns\n",
    "gp_comp_df = gp_comp_df[['ticker', '11/26-11/27_peak']].astype({'ticker': str, '11/26-11/27_peak': float})\n",
    "\n",
    "print(gp_comp_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistic: 62.0\n",
      "p value: 0.1405\n"
     ]
    }
   ],
   "source": [
    "#For peak movement 11/23-11/25\n",
    "\n",
    "just_gp_peak = gp_comp_df.loc[0, '11/26-11/27_peak']\n",
    "rest_peak = gp_comp_df['11/26-11/27_peak'][1:]\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "print(f'Mann Whitney U Statistic: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1405\n",
      "Hodges-Lehmann Estimator: 10.99\n",
      "Confidence Interval: (np.float64(-74.01), np.float64(7.94))\n"
     ]
    }
   ],
   "source": [
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n = len(pairwise_differences)\n",
    "\n",
    "    _, u_stat = mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "    lower_rank = int(max(0, u_stat - 1.96 * np.sqrt(n)))  # Ensure lower rank is >= 0\n",
    "    upper_rank = int(min(n - 1, u_stat + 1.96 * np.sqrt(n)))  # Ensure upper rank < n\n",
    "\n",
    "    lower_bound = pairwise_differences[lower_rank]\n",
    "    upper_bound = pairwise_differences[upper_rank]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative = 'two-sided')\n",
    "\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann Whitney U Statistics: 62.0\n",
      "p value: 0.1405\n",
      "Hodges-Lehmann Estimator: 10.99\n",
      "Confidence Interval: (np.float64(10.99), np.float64(11.38))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "##Perplexity version\n",
    "def hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05):\n",
    "    if np.isscalar(just_gp_peak):\n",
    "        just_gp_peak = [just_gp_peak]\n",
    "    if np.isscalar(rest_peak):\n",
    "        rest_peak = [rest_peak]\n",
    "\n",
    "    pairwise_differences = [x1 - x2 for x1 in just_gp_peak for x2 in rest_peak]\n",
    "    pairwise_differences.sort()\n",
    "\n",
    "    hl_estimator = np.median(pairwise_differences)\n",
    "\n",
    "    n1, n2 = len(just_gp_peak), len(rest_peak)\n",
    "    n = n1 * n2\n",
    "\n",
    "    # Calculate the critical value\n",
    "    z = stats.norm.ppf(1 - alpha/2)\n",
    "\n",
    "    # Calculate the standard error\n",
    "    se = np.sqrt((n1 + n2 + 1) / (12 * n1 * n2))\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    margin = z * se * np.sqrt(n)\n",
    "    lower_rank = int(np.ceil((n - margin) / 2) - 1)\n",
    "    upper_rank = int(np.floor((n + margin) / 2) - 1)\n",
    "\n",
    "    lower_bound = pairwise_differences[max(0, lower_rank)]\n",
    "    upper_bound = pairwise_differences[min(n - 1, upper_rank)]\n",
    "\n",
    "    return {\n",
    "        \"Hodges-Lehmann Estimator\": hl_estimator,\n",
    "        \"Confidence Interval\": (lower_bound, upper_bound)\n",
    "    }\n",
    "\n",
    "# The rest of your code remains the same\n",
    "u_stat, p_value = stats.mannwhitneyu(just_gp_peak, rest_peak, alternative='two-sided')\n",
    "\n",
    "result = hodges_lehmann_interval(just_gp_peak, rest_peak, alpha=0.05)\n",
    "print(f'Mann Whitney U Statistics: {u_stat}')\n",
    "print(f'p value: {p_value:.4f}')\n",
    "print(f\"Hodges-Lehmann Estimator: {result['Hodges-Lehmann Estimator']}\")\n",
    "print(f\"Confidence Interval: {result['Confidence Interval']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined p-value using Fisher's method: 0.0428\n"
     ]
    }
   ],
   "source": [
    "#For combining peak movement p - values\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def fisher_combined_pvalue(p_values):\n",
    " \n",
    "    chi2_stat = -2 * np.sum(np.log(p_values))\n",
    "\n",
    "    df = 2 * len(p_values)\n",
    "\n",
    "    combined_p_value = 1 - chi2.cdf(chi2_stat, df)\n",
    "\n",
    "    return combined_p_value\n",
    "\n",
    "p_values = [0.0928, 0.1143, 0.1405]  # List of individual p-values\n",
    "combined_p_value = fisher_combined_pvalue(p_values)\n",
    "\n",
    "print(f\"Combined p-value using Fisher's method: {combined_p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
